## 操作系统

#### CPU的执行顺序

存储单元、控制单元、运算单元。

* 存储单元用于存放数据；
* 控制单元用于识别字符是数据还是指令，以及控制程序的流程等
* 运算单元用于执行运算指令

识别器通过识别头将识别的字符交个控制单元，然后控制单元字符还是指令交给存储设备或者是运算单元。

### 硬件结构

根据冯诺依曼模型定义5个部分，<font color="#304ffe">运算器</font>、<font color="#304ffe">控制器</font> 、<font color="#304ffe">存储器</font>、<font color="#304ffe">输入设备</font>、<font color="#304ffe">输出设备</font>

运算器、控制器就是在中央处理器的，存储器就是常见的内存，输入输出设备是计算机外接的设备

中央处理单元通过总线和存储单元、以及输入输出单元进行交流。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png)

#### 内存

程序和数据都是运行在内存里的，存储的区域是线性的。

计算机数据存储中，存储数据的基本单位是<font color="#304ffe">字节</font> （byte） 一个字节等于8位 8bit。每一个字节都对应一个内存地址。

内存地址是从0开始编写，然后自增排列，最后一个地址为内存总字节数 -1，结构类似数组，读取任意一个数据的速度都是一样的。

#### 中央处理器

32位和64位CPU的主要区别在于一次能够计算多少字节的数据（注：1个字节等于8位）

* 32位CPU一次可以计算4个字节
* 64位CPU一次可以计算8个字节

32位、64位，表示的是CPU的位宽，代表一次可以计算的（运算）的数据量。

**区别在于**：

如果是一个8位的CPU，那么它只能计算1字节的范围内的运算` 0~255` 

```
0~255怎么来的？
首先：1个字节等于8位/ 8bit（比特）
每一个比特/位存储一个0或者1 （它是二进制位）
所以8比特的最大值就是 1111 1111 转换成10进制就是 1 + 2+ 4+ 8 + 16 + 32 + 64 + 128
此时等于 255 最小值 则为每一位都是0 那最后结果就是0
```

所以就无法<font color="pink">一次</font>计算大于255的运算。所以为了能一次计算大数的运算，CPU需要支持多个字节进行一起运算，所以CPU位宽越大，可以计算的数值就越大。

既然有了内存，那为什么还需要寄存器呢？

因为内存距离CPU太远了，寄存器就在CPU里，同时紧挨着控制单元和逻辑运算单元。

常见的寄存器种类：

* <font color="#c849ff">通用寄存器</font>： 用来存放需要运算的数据。
* <font color="#c849ff">程序计数器</font>： 用来存储CPU要执行下一条指令「所在的内存地址」。此时指令还在内存中，程序计数器记录的是内存地址/
* <font color="#c849ff">指令寄存器</font>： 用来存放当前正在执行的指令，也就是指令本身，指令在执行完之前，都存在这里。



#### 总线

总线是CPU和内存以及其他设备之间的通信，一般分成3种：

* <font color="#c849ff">地址总线</font>： 用于指定CPU将要操作的内存地址；
* <font color="#c849ff">数据总线</font>： 用于读写内存的数据
* <font color="#c849ff">控制总线</font>： 用于发送和接受信号。  

流程为：通过地址总线来指定内存地址，然后通过控制总线来控制读或者写。最后通过数据总线来传输数据。



#### 线路位宽与CPU位宽

**数据如何通过线路进行传输呢？ ** 其实通过操作电压，低电压表示0，高电压表示1。

（线路位宽的意义）

问题：

此时传输 5（十进制）， 就需要传输 101 这样的二进制数据。如果只有1条线路。意味着每次只能传递1bit的数据，那么传送完101， 就需要3次。 这样一位一位的传输就称为<font color="pink">串行</font> 。下一bit必须等上一个bit传输完才能进行传输。 在此模式下如果想要多传一些数据，就需要增加线路。

Cpu 想要操作「内存地址」就需要 「地址总线」

* 如果地址总线只有1条，那每次只能表示「0 或 1 」这两种地址，所以CPU 能操作的内存最大地址数为2 （2^ 1） 条 （不能理解 同时操作 2个内存地址，是种类）
* 如果地址总线有2条，那么就能表示 00、01、10、11 这四种地址，所以CPU能操作的内存地址最大总量为 4 （2^ 2 ） 个

 那么，就要CPU操作4G 大的内存，那么就需要32条地址总线 因为 ` 2 ^ 32 = 4G` 

 

CPU位宽的意义

如果用32位CPU去加 和 两个64位大小的数字，就需要把这2个64位的数字分成2个低位32位数字和2个高位数字来计算，先加两个低位的32位数字，算出进位。然后加和两个高位的32位数字。最后再加上进位，就能算出结果。也就是说，32位CPU并不能一次性计算加和两个64位的数字结果。

<font color="pink"> 如果计算和数额不超过32位数字的情况下，32位和64位CPU之间没有什么区别，只有当计算超过32位数字的情况下，64的优势才能体现出来</font>

另外，32位CPU最大能操作4GB内存，就算装了8GB内存条也没用。而64位CPU寻址范围很大，理论上的寻址空间位 `2 ^ 64` 4GB * 4 GB



#### 程序执行的基本过程

程序实际上是一条一条指令，所以程序的运行过程就是把一条指令一步一步的执行起来，负责指令的就是CPU了。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/CPU%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F.png)

CPU执行步骤

* 第一步，CPU读取「程序计数器」的值，(指令的内存地址)   然后CPU的「控制单元」 操作 「地址总线」 指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」 将指令数据传给CPU， CPU 收到内存传来的数据后，将这指令数据存入到「指令寄存器」.
* 第二步，「程序计数器」的值自增，表示执行下一条指令，这个自增的大小，由CPU的位宽决定，比如32位的CPU，指令是4个字节，需要4个内存地址存放，因为「程序计数器」的值会自增4；
* 第三步， CPU分析「指令寄存器」中的指令，确定指令类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」 运算；如果是存储类型的指令，则交由「控制单元 」执行吧;

##### 以a= 1+ 2为例

编译器会把` a=1+2` 翻译成4条指令，存放到正文段中。![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E6%95%B0%E6%8D%AE%E6%AE%B5%E4%B8%8E%E6%AD%A3%E6%96%87%E6%AE%B5.png)

* 0x100 的内容是` load`指令将0x200地址中的数据1装入到寄存器` R0`;
* 0x104 的内容是` load`指令将0x204地址中的数据2装入到寄存器` R1`；
* 0x108的内容是 ` add` 指令将寄存器` R0`和` R1`的数据相加，并把结果存放在寄存器` R2`；
* 0x10c的内容是 `store`指令将寄存器` R2`中的数据存回数据段中的0x208地址中，这个地址就是变量`a`内存中的地址;



编译完成后，具体执行程序的时候，程序计数器就会被设置0x100地址，然后一次执行这4条指令。

由于是在32位CPU执行的，因此一条指令是占32位大小，所以会发现每条指令间隔4个字节。

而数据大小是根据程序中指定的变量类型，比如` int` 类型的数据占4个字节，`char`类型的数据则占1个字节。



现在大多数CPU都是按照流水线的方式来执行命令，所谓流水线就是把一个任务拆分称多个小任务，于是一条指令通常分为4个阶段，称为4级流水。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/CPU%E6%8C%87%E4%BB%A4%E5%91%A8%E6%9C%9F.png)

四个阶段的具体含义：

1、CPU通过程序计数器读取对应的内存地址的指令，这个部分称为<font color="pink">Fetch（获取指令）</font>  

2、CPU对指令进行解码，这部分称为<font color="pink">Decode（指令译码）</font>

3、CPU执行指令，这个部分为<font color="pink">Execution（执行指令）</font>

4、CPU将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为<font color="pink">Store（数据回写）</font>

上面4个阶段，称为<font color="pink">指令周期（</font><font color="orange">Instrution Cycle</font><font color="pink">）</font>CPU的工作就是一个周期接着一个周期周而复始。如此循环。

##### 指令的执行速度

CPU的硬件参数都会有`GHz`这个参数，比如一个1GHz的CPU，指的是时钟频率是1G，代表着1秒会产生1G次的脉冲信号，每一次脉冲信号高低电平就是一个周期，称为时钟周期。

对于CPU来说，在一个时钟周期内，CPU仅仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度就越快。

注意⚠️： 一个时钟周期，不一定能完成一条指令，大多数指令不能在一个是时钟周期完成，通常需要若干个时钟周期，不同的指令需要的时钟周期是不同的。加法和乘法都对应着一个条CPU指令，但是乘法需要的时钟周期要比加法的多。



程序执行的时候，耗费的CPU时间少，就说明程序是快的，对于程序的CPU执行时间，可以拆解成<font color="pink">CPU时钟的周期数（<font color="orange">CPU Cycles</font>和时钟周期时间（<font color="orange">Clock Cycle Time</font>）的乘积</font>

时钟周期是由电脑的主频决定的。而CPU时钟周期同样也可以提高程序的性能。



对于CPU时钟周期，可以进一步拆解成： 「<font color="purple">指令数 X 每条指令的平均时钟周期数（  简称CPI）</font>」

于是CPU的执行公式变成了

**程序的CPU执行时间= 指令书 x CPI  x  时钟周期时间**

所以要想程序跑的更快，优化这三者即可：

* 指令数，表示执行程序所需要多少条指令，以及那些指令。这个需要编译器来优化，因为同样的指令，在不同的编译器，编译出来的计算机指令会有各种不同的表达方式。
* 每条指令的平均时间周期数CPI, 表示一条指令需要多少个时钟周期数，现代大多数CPU通过流水线计数（Pipeline），让一条指令需要的CPU时钟周期数尽可能的少。
* 时钟周期时间，表示计算机主频，取决于计算机硬件，有的CPU支持超频技术，意味着把CPU内部的时钟调快了， 所以CPU工作速度就变快了。



#### 磁盘和内存的速度

Question: 机械硬盘、固体硬盘、内存这三个存储器，到底和CPU L1 Cache 相比速度差多少倍呢？

##### 存储器的层次结构

CPU Cache，中文称CPU高速缓存，处理速度比寄存器慢一些。

CPU Cache通常会分为L1、L2、L3三层，其中L1Cache通常分成 「数据缓存」和「指令缓存」，L1是距离CPU最近的，因此它比L2、L3的读写速度都快、存储空间都小。

寄存器和CPU Cache 都是在CPU内部，跟CPU挨着近，因此它们的读写速度都比较快，但是由于CPU比较小，能够存储的数据很少。

硬盘流程

数据从硬盘加载到内存，再从内存加载到CPU的寄存器和Cache 中，然后再通过CPU进行处理和计算

<font color="pink">对于存储器、它的速度越快、能耗越高、而且材料的成本也是越贵的，以至于速度快的存储器容量都是比较小的</font>

存储器可以分为这几个级别

* CPU级
  * 寄存器
  * L1 Cache
  * L2 Cache
  * L3 Cache
* 内存
* SSD/ HDD 硬盘



##### 寄存器

最靠近CPU的控制单元和逻辑计算单元的存储器就是寄存器。

寄存器的数量通常在几十到几百之间，每个寄存器可以用来存储一定字节（byte）的数据

* 32位CPU中大多数寄存器可以存储` 4`个字节
* 64位CPU中大多数寄存器可以存储`8` 个字节

寄存器的访问速度非常快，一般要在半个CPU时钟周期内完成读写，CPU时钟周期跟CPU主频 息息相关，

CPU处理一条指令的时候，除了读写寄存器，还需要解码指令，控制指令执行和计算，如果寄存器的速度太慢，则会拉长指令的处理周期，从而给人种很慢的感觉。

##### CPU Cache

CPU Cache用的是一种叫 <font color="pink">SRAM</font>  (Static Random-Access Memory， 静态随机存储器)的芯片。

SRAM之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，一点断电，数据就会丢失。

在SRAM中，一个bit的数据，通常需要6个晶体管，所以SRAM的存储密度不太高，同样的物理空间，能存储的数据是有限的。

CPU 的高速缓存，通常可以分成L1、L2、L3这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/CPU-Cache.png)



##### L1 高速缓存

L1高速缓存的速度几乎和寄存器一样快，通常只需要` 2~4`个周期，而大小在几十KB到几百KB不等。

每个CPU核心都有一块属于自己的L1高速缓存，指令和数据在L1时分开存放的，所以L1高速缓存通常分成<font color="purple">指令缓存</font> 和<font color="purple">数据缓存</font>



##### L2高速缓存

L2高速缓存的位置比L1高速缓存的位置距离CPU更换，它的大小比L1高速缓存更大，CPU型号不同大小不同，通常在几百KB到几MB不等，访问速度更慢，速度在` 10～20`个时钟周期



##### L3高速缓存

L3高速缓存通常是多个CPU核心公用的，位置比L2高速缓存距离CPU核心更远，大小也会更带些，通常在几MB到几十MB不等，具体根据CPU型号而定。访问速度也慢一些，在` 20～60`个时钟周期



#### 内存

内存用的芯片和CPU Cache有所不同，它使用的是一种叫做 DRAM(Dynamic Random Access Memory 动态随机存取存储器)的芯片。

相比SRAM，DRAM的密度更高，功耗更低，有更大的容量，而且造价相比SRAM芯片 便宜的多，

DRAM存储一个bit数据，只需要一个晶体管和一个电容就能存储，但是因为数据就会存储在电容里，电容会不断漏电，所以需要「定时刷新」电容， 才能保证数据不会被丢失，这就是DRAM之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。

DRAM的数据访问电路和刷新电路都比SRAM更复杂，所以访问速度会更慢，内存速度大概在` 200～300`个时钟周期之间



#### SSD/HDD 硬盘

SSD（Solid-state disk），其结构和内存类似，但是它的优点是，断电了后数据还是存在的。而内存、寄存器、高速缓存断电后数据都会丢失，内存的读写速度大概比SSD大概快`10～1000`倍。

还有一些机械硬盘（Hard DIsk Drive HDD）他是通过物理读写的方式来访问数据的，因此它访问的速度是非常慢的，他的速度比内存慢`10W`倍左右



#### 存储器的层次关系

CPU不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道。

比如，CPU Cache 的数据是从内存加载过来的，写回数据的时候也只能写回到内存，CPU Cache不会直接把数据写入到硬盘中，也不会直接从硬盘中加载数据，而是先加载到内存，然后再从内存加载到CPU Cache中。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB%E5%9B%BE.png)



所以：<font color="purple"> 每个存储器只能和相邻的一层存储设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以CPU内部的寄存器， L1、L2、L3 Cache 只好用较小的容量，相反内存，硬盘则可以用更大的容量</font>



##### 如何写出CPU跑的更快的代码

CPU内部嵌入了CPU Cache (高速缓存),它的存储容量很小，但是离CPU核心很近，所以缓存的读写速度是极快的。如果CPU 运算时，直接从CPU Cache 读取数据，而不是从内存的话，运算速度就会很快。



根据现在情况所知（2023-03-20）一次内存访问所需时间是` 200～300` 多个时钟周期，这意味着CPU和内存的访问速度已经相差了` 200～300`多倍，

为了弥补差距就有了CPU Cache。

##### CPU Cache的数据结构是什么样的？

CPU Cache是由很多个Cache Line 组成的，Cache Line 是CPU 从内存读取数据的基本单位，而Cache Line是由各种标志（Tag）+ 数据块（Data Block）组成的。
CPU Cache 的数据是从内存读取来的，它是以一小块小块读取数据的，而不是按照单个数组元素来读取的，在CPU Cache中，这样小块叫做 Cache Line 缓存块。

根据L1 Cache的大小，可以知道一次载入的数据大小

```
cat /sys/devices/system/cpu/cpu0/cache/index0/chherency_line_size
64
```

可以看出主机L1 Cache Line 的大小，也就意味着<font color="purple">L1 Cache 一次载入数据的大小是64字节</font>



比如：

有一个` int array[100]` 的数组，当载入` array[0]`时，由于这个数组元素的大小在内存只在4字节，不足64字节，CPU就会<font color="purple">顺序加载</font>数组元素到`array[15]`，意味着`array[0]～array[15] `数组元素都会被缓存在CPU Cache中，因此当下次访问这些数组元素时，会直接从CPU Cache读取，而不用再从内存读取，大大提供提高了CPU读取数据的性能。

事实上，CPU读取数据的时候，无论数据是否存放在Cache中，CPU都是先访问Cache，只有当Cache中找不到数据时，才回去访问内存，并把内存中的数据读取到Cache中，CPU再从CPU Cache 读取数据。



##### CPU如何知道要访问的数据在没在Cache中呢？

1、 <font color="purple">直接映射Cache</font>

我们知道，CPU访问内存数据时，是一小块一小块数据读取的，具体一小块数据大小，取决于，

`coherency_line_size` 的值，一般是64字节，在内存中，这一块的数据称为<font color="purple">内存块</font>读取的时候拿到的是数组所在的内存的地址。

对于直接映射Cache采用的策略，就是把内存块的地址始终「映射」在一个CPU Cache Line（缓存块）的地址，至于映射关系实现方式，则是实用「取模运算」，取模运算的结果就是内存地址对应CPU Cache Line （缓存块）的地址

举个例子

内存被换分为`32`个内存块，CPU Cache 共有`8个`CPU Cache Line，假设CPU想要访问第15号内存块，如果15号内存块中的数据已经缓存到CPU Cache Line 中的话，则一定是映射在7号CPU Cache Line 中，因为 `15% 8`的值是7。  那么如果按照取模运算，除了15号内存块是映射在7号CPU Cache Line 中，还有7号、23号、31号内存都是映射到7号CPU Cache Line 中.

因此，为了区别不同的内存块，在对应的CPU Cache Line中我们还会存储一个<font color="purple">组标记 Tag</font>。这个组标记会记录当前CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。

除了组标记信息外，CPU Cache Line 还有两个信息：

* 一个是，从内存加载过来的实际存放数据（Data）
* 另一个是，有效位（Valid bit）它是用哪里标记对应的CPU Cache Line是否有数据，如果有效位是0，无论CPU Cache Line中是否有数据，CPU都会直接访问内存，重新加载数据。